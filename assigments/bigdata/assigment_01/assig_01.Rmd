---
title: "Digital Earth: Big Earth Data Concept - assignment I"
author:
- name: "<b>Name:</b> Cesar Luis Aybar Camacho (s1078735)"
- name: "<b>Program:</b> Erasmus Copernicus Master in Digital Earth"
date: '<b>Date:</b> `r format(Sys.time(), "%d %B, %Y")`'
output:
  bookdown::gitbook:
    includes:
      in_header: header.html
---

```{r setup, include=FALSE}
library(dplyr)
library(kableExtra)
library(formattable)
library(crayon)
knitr::opts_chunk$set(echo = TRUE)
```

```{r htmlTemplate, echo=FALSE}
# Create the external file
img <- htmltools::img(src = "https://user-images.githubusercontent.com/16768318/96349562-be6c7700-10b0-11eb-973d-ce55906dcf7e.jpeg", 
               alt = 'logo', 
               width="10%",
               style = 'position:absolute; top:50px; right:1%; padding:10px;z-index:200;')

htmlhead <- paste0('
<script>
document.write(\'<div class="logos">',img,'</div>\')
</script>
')

readr::write_lines(htmlhead, path = "header.html")

```

# Question N° 01

**Name and explain some common characteristics of the three different ARD definitions / approaches.**

**A**nalysis-**r**eady-**d**ata (**ARD**) is a new trends among satellite imagery providers  that consist in create fully harmonized dataset, with the intention 
that, final users only have to worry about data analysis ([Andreia Siqueira et al. 2019](https://paperpile.com/app/p/5ef2ffac-56a6-0d82-8bd6-b32c3b83a8b5)).

The Committee on Earth Observation Satellites (CEOS) has develop the **framework**
CEOS Analysis Ready Data (**CARD4L**) for Optical Surface Reflectance (**CARD4L-OSR**), Surface Temperature (**CARD4L-ST**) and Normalized Radar Backscatter (**CARD4L-NRB**). Unlike **Planet** the **U.S. Geological Survey (USGS)** have been involved on the development of **CARD4L** and it is part of CEOS (See the next [note](https://www.usgs.gov/center-news/usgs-eros-landsat-play-major-roles-development-ceos-card4l)).

The table below summarize some shared characteristic between the ARD implemented by [Planet](https://www.planet.com/pulse/planets-framework-for-analysis-ready-data/), and [USGS](https://www.usgs.gov/core-science-systems/nli/landsat/us-landsat-analysis-ready-data).

```{r echo=FALSE,results='asis'}
features <- c(
  "Clipping",
  "Cloud Masks",
  "Rad. Correction",
  "Atm. Correction",
  "Pixel Alignment",
  "Sensor normalization",
  "Products"
)
ARD <- c("Planet", "USGS")
table_q1 <- matrix(1, length(ARD), length(features))  %>% as.data.frame()
colnames(table_q1) <- features
rownames(table_q1) <- ARD

table_q1$"Clipping" <- c(1, 1)
table_q1$"Cloud Masks" <- c(0, 1)
table_q1$"Rad. Correction" <- c(1, 1)
table_q1$"Atm. Correction" <- c(0, 1)
table_q1$"Pixel Alignment" <- c(1, 1)
table_q1$"Sensor normalization" <- c(1, -1)
table_q1$"Products" <- c("Planetscope, RapideEye and Skysat", "Landsat")

table_q1[table_q1 == -1] = cell_spec("x", color = "red", bold = T, align = "center")
table_q1[table_q1 == 0] = cell_spec("nc", color = "#d4bb00", bold = T, align = "center")
table_q1[table_q1 == 1] = cell_spec("✓", color = "green", bold = T, align = "center")

kbl(table_q1, escape = F) %>% 
  kable_paper("hover", full_width = F) %>% 
  column_spec(5, width = "3cm") %>% 
  footnote("nc means not fully available for all their products.", footnote_as_chunk = T)
```

As can be seen, **Planet** and **USGS** (**CARD4L**) ARD implementations are quite similar. The main difference is that Planet also considering **Sensor-to-Sensor Normalization** which refer to the capacity of align spectral data from different sensors (See [Chander et al. 2013 ](https://paperpile.com/app/p/3796466f-b2cc-04aa-a4bd-1ded1db8f2ca)). 

Finally is important to notice that the **USGS** ARD is only available at the conterminous United States, Alaska and Hawaii.

**Explain in your own words why satellite data provider found it necessary to investigate how ARD can be created and delivered to users.**

In my opinion, there are two main reasons:

- **Massive increase of satellite images which will soon be impossible to handle**; approaches like ARD dramatically reduce processing time, facilitate 
reproducible research pipelines and thereby accelerate science production.

- **Ease of use for remote sensing non-expert**. ARD make possible, for instance, computer vision experts can build deep learning models despite not having knowledge about satellite image pre-processing.

# Question N° 02

**Summarize in a short paragraph the main elements of the ESA Sentinel-2 Level-2A specifications and how they are processed.**

ESA Sentinel-2 Level-2A in comparison to Level-1C present two principal improvements. The Atmospheric Correction which convert values from TOA to BOA 
(based on the LIBRADTRAN radiative transfer model) and an additional band 
called **Scene Classification** (SC). SC is a  pixels classification map which
is useful, for instance, to mask cloud and cloud shadow values. 

<center>
<img src = img/download.png width=35%>
<br>
Scene Classification Values
</center>


**Are Level-2A data available for all areas at the moment?**

According to ESA the Sentinel-2 level-2A global coverage production started in December 2018. See this [link](https://earth.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-2a-processing).

**What is “Sen2Cor”?**

In a nutshell, Sen2Cor is a software maintained by ESA that permit generate 
Sentinel-2 Level 2A products from Level 1C products.

# Question N° 03

**Describe how Theia produces and distributes Level-2A data, corrected for atmospheric effects thanks to the MAJA software developed in coordination between CNES/CESBIO and DLR.**

**MACCS** (Multi-sensor Atmospheric Correction and Cloud Screening) combined with 
**ATCOR** (Atmospheric and Topographic Correction) generated **MAJA** 
(MACCS-ATCOR Joint Algorithm) a software develop and maintain by  CNES, CESBIO and DLR. For Sentinel-2 Level-2A, **MAJA** only covers France, Germany and other specific requested areas in the world.

For convert TOA to BOA values, **MAJA** contains module to estimate the H20 content and correct the atmospheric absorption (See [SMAC](https://labo.obs-mip.fr/multitemp/python/smac-atmospheric-correction-python/)). Inspired in ATCOR, also correct the influence of the slope and adjancency effect.

For cloud detection, **MAJA** works with multiple images (time-series) due this method assume surface reflectances without clouds are stable in time, while clouds or cloud shadows result in quick variations. However, it assumption could be a problem in almost always cloud cover regions like the Peruvian Amazon.




**Describe the main differences in the production chains compared to the ESA Level-2A data.**

Unlike **Sen2Cor**, **MAJA** 


The method assumes that surface reflectances without clouds are stable in time, while clouds or cloud shadows result in quick variations. MAJA
uses multi-temporal images that contain the most recent cloud-free observation for each pixel.
At each new image, the algorithm updates this composite with the newly-available cloud-free pixels.
Thus, it processes the data for a given location in chronological order. The algorithm needs to be
initialized to fix cases where a given pixel has no cloud-free observations. To cover these specific cases, MAJA also uses a mono-temporal criterion based only on spectral information.